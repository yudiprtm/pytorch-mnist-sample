{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library\n",
    "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:06<00:00, 1495660.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2122517.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 64 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import matplotlib.pyplot as plt\n",
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.1\n",
    "momentum = 0.00002\n",
    "device = \"cpu\"\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12968\\1895196525.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm(train_loader, total=int(len(train_loader)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3634f4e5038745358d85395b4592bf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12968\\4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1675, Accuracy: 9506/10000 (95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d6c2e19e234bf29b999731a4f3fcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1242, Accuracy: 9634/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ebbd1a42474e81b6253234cac804b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1014, Accuracy: 9701/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12968\\4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
